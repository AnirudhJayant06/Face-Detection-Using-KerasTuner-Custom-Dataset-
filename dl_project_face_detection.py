# -*- coding: utf-8 -*-
"""DL Project: Face Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TFShGnh-u_JDTDPxNdqBsHYKv1rtnfb5

# Imports
"""

import tensorflow as tf
import os
import pandas as pd
import numpy as np

"""# Making Use of Colab GPUs

**Before executing this file, go to 'Runtime' -> 'Change runtime type' -> 'Hardware accelerator' -> Select 'GPU' -> Click 'Save'**
"""

# To check no. of GPUs
tf.test.gpu_device_name()

# To list all the available devices (CPU + GPU)
from tensorflow.python.client import device_lib
device_lib.list_local_devices()

"""# Uploading CSV file

These are customized dataset made by combing CIFAR-100 & other dataset of faces from Kaggle.

Steps taken to build this dataset:
1. From CIFAR-100, I compared names from CSV file with the names of the images in the image folder and, then, created a new Dataframe with columns ranging from 0 to 1023 & last column is 'y' in which I append these images in array format (RGB -> Grey Scale -> Resize to 32x32 -> Flatten) and also the value of y, '1' if image belongs to people class & '0' otherwise which makes this dataset unbalanced (skewed dataset).

2. To overcome this probelm, I tried to balance this dataset with a different dataset of face images downloaded from kaggle containing 70k images.

3. Now, I removed all the images from the existing dataset with y=1 which reduced this dataset to 47,550 data samples.Then, I took 47,550 images (randomly picked) from 70k dataset of faces,  format the images as per the requirement (RGB -> Grey Scale -> Resize to 32x32 -> Flatten) and append it to this dataset with y =1.

4. This makes it a dataset with 95100 examples with equal no. of face & non-face images with dataset shape = 95100 x 1025

5. Finally, I exported this dataframe as a CSV file which we are using here.
"""

# Creating a directory
!mkdir FacevsNotAFace

# Commented out IPython magic to ensure Python compatibility.
# Moving to the desired folder where we want to upload files
# %cd /content/FacevsNotAFace

# To resolve the problem of 'Access Denied'
!pip install --upgrade --no-cache-dir gdown

"""Google Drive Link of the CSV files: https://drive.google.com/drive/u/1/folders/1ZzKjU-92A93WZg9xTbqZX02kE_FLwDC9

"""

# Downloading Dataset CSV File
! gdown 1zOQ5CSKn-gAVaf-NdEe7R1pf8QURwUGV

"""# Visualizing, Analysing & Preparing Data

## Dataset
"""

# Loading CSV file
Database = pd.read_csv('/content/FacevsNotAFace/Dataset_Face_Detection.CSV')

# Converting float values to int
Database = Database.apply(np.int64)

# Shuffling Data multiple times - Helpful when we do data split - Train, CV & Test
for i in range(10):
  Database = Database.sample(frac = 1)

# Reset index
#Database.reset_index(inplace=True, drop=True)

# Data after removing 1st two redundant columns
Database.drop(Database.columns[[0,1]], axis=1, inplace=True)

print('Dataset Snippet: \n',Database.head())
print('\n Column names: ',Database.columns)
print('\nDataset Shape: ',Database.shape)

"""# Split Database into Training & Test Data

This is done using train_test_split from scikit learn
- By Mentioning random_state, it 'll result in same output everytime.
"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Splitting Data
Train_Database, Test_Database = train_test_split(Database, test_size = 0.25, random_state=1)

"""# Creating Input & Output Data

## Training Data
"""

X_Train = Train_Database.iloc[:,:1024]
y_Train = Train_Database.iloc[:,1024:1025]

print('Training Data \n')

print('X size: ',X_Train.shape)
print('X: \n',X_Train.head())

print('y size: ',y_Train.shape)
print('y: \n',y_Train.head())

"""## Test Data"""

print('Size of Test Database: ',Test_Database.shape)

X_Test = Test_Database.iloc[:,:1024]
y_Test = Test_Database.iloc[:,1024:1025]

print('X_Test shape: ',X_Test.shape)
print('X_Test Data: \n',X_Test.head())

print('y_Test shape: ',y_Test.shape)
print('y_Test Data: \n',y_Test.head())

"""# Feature Scaling Using Scikit Learn (Standard Scaler)

Feature scaling is not required in this as all the features have same range of values but we still do it as it makes training faster.
"""

# fit_transform vs transform: https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe


from sklearn.preprocessing import StandardScaler

fc = StandardScaler()

X_Train = fc.fit_transform(X_Train)
X_Test = fc.transform(X_Test)

print('X_Train size: \n',X_Train.shape)
print('\n X_Test size: \n',X_Test.shape)

print('\nX_Train Data snippet: \n',X_Train)
print('\n X_Test Data snippet: \n',X_Test)

"""# Creating, Compiling & Training a model using Keras Tuner


"""

# Commented out IPython magic to ensure Python compatibility.
# To go to the desired directory
# %cd '/content/'

# Downloading keras tuner
!git clone https://github.com/keras-team/keras-tuner

# Making a directory and installing keras
# %cd keras-tuner
!pip install keras-tuner

# Necessary imports

from tensorflow import keras
from tensorflow.keras import layers
from keras_tuner import tuners
from keras_tuner.tuners import RandomSearch

"""## Defining a model with search space for keras tuner"""

# Defining a model with search space for keras tuner

# This function returns a compiled Keras Model. 
# 'hp' is an argument for defining the hyperparameters while building the model.

def build_model(hp):

  # Initializing a sequential model
  model = keras.Sequential()

  # Creating a for loop to create multiple models with different no. of layers
  for i in range(hp.Int('num_layers', 2,20)):

    model.add(
           layers.Dense(
          
              # Tuning no. of units - To tune the number of units in different Dense layers
              # separately as different hyperparameters, we give them different names
              units=hp.Int('units' + str(i), min_value = 32, max_value = 512, step = 32),

              kernel_initializer = 'he_uniform',
              activation = 'relu',
              )
           )
       
    # if hp.Boolean('dropout'):
    #     model.add(layers.Dropout(rate=0.25))
      
  # Adding a dropout layer
  # Rate - Float between 0 and 1.
  #      - Fraction of the input units to drop.
  
    
  # Adding output layer
  model.add(layers.Dense(1, kernel_initializer = 'glorot_uniform', activation='sigmoid'))

  # Compiling the model
  model.compile(
      optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2,1e-3,1e-4])),
      loss = 'binary_crossentropy',
      metrics = ['accuracy'])
  
  return model

"""## Initializing Keras Tuner"""

# Commented out IPython magic to ensure Python compatibility.
# Loading TensorBoard notebook extension
# %load_ext tensorboard

import datetime

# Clear any logs from previous runs
!rm -rf ./logs/

import keras_tuner

tuner = RandomSearch(
    
    # Calling the method
    build_model,
    objective = 'val_loss',
    max_trials = 5,

    # This is the no. of model that should be built and fit for each trial.
    # Different trials have different hyperparameters values but executions w/n
    # the same trial have the same hyperparameter values.
    # Multiple executions per trial helps to reduce results variance and, therefore,
    # be able to assess the performance of a model more accuractely.
    executions_per_trial = 3,

    # Directory to store the intermediate results.
    directory = '/tmp/tb',

    project_name = 'Face Detection')

# Tuner Summary

tuner.search_space_summary()

"""## Start the Search"""

# Start the search

tuner.search(
    X_Train,
    y_Train,
    epochs = 10,
    validation_split = 0.2,

    # Using TensorBoard callback
    # The logs 'll be write to '/tmp/tb_logs'
    callbacks = [keras.callbacks.TensorBoard('/tmp/tb_logs')],
    )

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir /tmp/tb_logs

"""## Model Selection & Model Building"""

# Getting top 2 performing models 
tuned_models = tuner.get_best_models(num_models=2)

# Selecting the best performing model
best_model = tuned_models[0]

# Defining the input shape - needed for sequential model
best_model.build(input_shape = (None, 1024))

best_model.summary()

"""# Check prediction of the model"""

# Prediction on Test Data
y_pred = best_model.predict(X_Test)
print('Shape of y_pred: ',y_pred.shape)
#print('\nActual y_pred Values: \n',y_pred)

# Since, we are using 'Sigmoid' activation function in the last layer which means
# to convert data into binary we can use 0.5 as a cutoff limit, where 
# values < 0.5 -> we 'll mark the value as 'False' which means '0', and if
# values >= 0.5 -> we 'll mark the value as 'True' which means '1'

y_pred = (y_pred >= 0.5)
#print('\nTrue or False y_pred Values: \n',y_pred)

i=0
no_of_humans = 0
for val in y_pred:
  if val == True:
    no_of_humans += 1
    #print('Value is True at: ',i)
  #i += 1

print('No of humans predicted: ',no_of_humans)

"""# Calculating Accuracy Score"""

# Accuracy Score
from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred,y_Test)

print('Accuracy Score: ',score)